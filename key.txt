NOTES:
gprof command: gprof -b -Q -T mireg_serial gmon.out > analysis.txt
perf command: perf stat -d ./mireg_serial SCAN_normal_refc_gray_1600.txt SCAN_normal_refc_gray_1619.txt reflectivity
perf command: perf record -g ./mireg_serial SCAN_normal_refc_gray_1600.txt SCAN_normal_refc_gray_1619.txt reflectivity
perf command: perf report -g "graph,0.5,caller"

TODO:
1. Move the implementation to cuda.
2. Bring in normal and all implementations.
3. Refine the algorithm remove pcl_helper support for finding the best fit plane.
4. Organize the code well.
5. Divide the data structure such that it fits L2 cache, and make processing pools for the reading points accordingly.

IDEAS:
1. Change the data structure from tree to a sorted level based nodes, binary search on the respective levels for the desired nodes, decompose the nodes on a given level into super nodes representing sqrt(no. of nodes in the given label(i.e. n)), so there will be approximately sqrt(n) super nodes, and after that make the binary search on the elements of the desired super node, whose size will be approximately sqrt(n), what this will do is reduce the size of the arrays to around 2-3 kb which will fit in L1 cache and no. of memory calls and l3 cache calls will reduce. Try precaching all the values into l3 cache. Inline the search implementation. Try it and reason if not giving any speed benefits. Check that results don't change. And if calculating mi is a problem, read the data inside the reference cloud in separate array as per the reading cloud. Preprocess the reading cloud to contain unsigned short int of x, y as grid coordinates instead of point coordinate, will reduce size.
2. Try removing unsigned wherever possible, and see if there are any unsigned overheads.
